{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo sourced from https://www.tensorflow.org/tutorials/quickstart/beginner\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train[:1]))\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    #Converts the input into a 1-dimensional array\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    #Adds 128 RELU neurons\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #Sets dropout, which mat will discuss if there's time, but basically it stops the model from relying on only one neuron\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    #Sets up the 10 linear output nerons\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.28293514\n",
      "1 -0.7047493\n",
      "2 -0.09524431\n",
      "3 0.28605023\n",
      "4 -0.5991763\n",
      "5 0.5610809\n",
      "6 0.06513612\n",
      "7 0.07550294\n",
      "8 -0.03698676\n",
      "9 0.694656\n"
     ]
    }
   ],
   "source": [
    "#Train & Predict on one sample\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "for i in range(10):\n",
    "    print(i, predictions[0,i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.115636006\n",
      "1 0.043067254\n",
      "2 0.0792231\n",
      "3 0.11599678\n",
      "4 0.04786267\n",
      "5 0.152718\n",
      "6 0.09300454\n",
      "7 0.09397372\n",
      "8 0.08397552\n",
      "9 0.17454249\n"
     ]
    }
   ],
   "source": [
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "for i in range(10):\n",
    "    print(i, probabilities[0,i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8791623"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2959 - accuracy: 0.9140\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1424 - accuracy: 0.9568\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1043 - accuracy: 0.9687: 1s - loss:\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0868 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0741 - accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c4948e708>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0813 - accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08129025995731354, 0.9750999808311462]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.9129420e-06 2.1373097e-08 5.2382352e-06 4.8524900e-05 4.1873338e-11\n",
      "  1.5301390e-06 1.5931029e-10 9.9992180e-01 1.8870367e-06 1.9045421e-05]\n",
      " [7.2775589e-07 4.6804204e-04 9.9939620e-01 9.6887699e-05 1.5480139e-14\n",
      "  3.2509135e-05 3.1805840e-08 5.7724950e-14 5.6445069e-06 3.1440384e-12]\n",
      " [4.4103177e-07 9.9855214e-01 3.5938960e-05 1.2692525e-05 2.2811005e-04\n",
      "  4.1428439e-06 3.5315166e-05 7.9786248e-04 3.2125384e-04 1.1894745e-05]\n",
      " [9.9992764e-01 6.9361836e-09 2.5000070e-05 1.1718314e-07 1.3878797e-09\n",
      "  1.4552453e-06 4.3611417e-05 1.5252789e-06 4.9448687e-08 6.1435776e-07]\n",
      " [1.5285659e-07 3.9460764e-09 1.6400846e-06 8.5131182e-09 9.9953461e-01\n",
      "  6.5084072e-07 9.6743588e-07 1.5094413e-05 1.3371786e-07 4.4684921e-04]], shape=(5, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "predictions = probability_model(x_test[:5])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(1.912942e-06, shape=(), dtype=float32)\n",
      "1 tf.Tensor(2.1373097e-08, shape=(), dtype=float32)\n",
      "2 tf.Tensor(5.238235e-06, shape=(), dtype=float32)\n",
      "3 tf.Tensor(4.85249e-05, shape=(), dtype=float32)\n",
      "4 tf.Tensor(4.1873338e-11, shape=(), dtype=float32)\n",
      "5 tf.Tensor(1.530139e-06, shape=(), dtype=float32)\n",
      "6 tf.Tensor(1.5931029e-10, shape=(), dtype=float32)\n",
      "7 tf.Tensor(0.9999218, shape=(), dtype=float32)\n",
      "8 tf.Tensor(1.8870367e-06, shape=(), dtype=float32)\n",
      "9 tf.Tensor(1.9045421e-05, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, predictions[0,i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
